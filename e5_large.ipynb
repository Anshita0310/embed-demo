{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac4f324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (5.2.2)\n",
      "Requirement already satisfied: qdrant-client in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (1.16.2)\n",
      "Requirement already satisfied: pandas in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (2.3.3)\n",
      "Collecting pandas\n",
      "  Using cached pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (79 kB)\n",
      "Requirement already satisfied: pyarrow in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (23.0.0)\n",
      "Requirement already satisfied: fastapi in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (0.128.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (4.57.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: numpy in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (2.2.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.1.15)\n",
      "Requirement already satisfied: requests in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from qdrant-client) (1.75.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from qdrant-client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from qdrant-client) (5.29.5)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from qdrant-client) (2.12.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from qdrant-client) (2.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from fastapi) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from fastapi) (0.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (80.4.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl (9.9 MB)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.3.3\n",
      "    Uninstalling pandas-2.3.3:\n",
      "      Successfully uninstalled pandas-2.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lseg-data 2.1.1 requires pandas<3.0,>=2.0, but you have pandas 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-3.0.0\n",
      "Requirement already satisfied: httpx<0.28 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (0.27.2)\n",
      "Collecting pandas<3.0\n",
      "  Using cached pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: anyio in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pandas<3.0) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pandas<3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pandas<3.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from pandas<3.0) (2025.2)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.28) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0) (1.17.0)\n",
      "Using cached pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 3.0.0\n",
      "    Uninstalling pandas-3.0.0:\n",
      "      Successfully uninstalled pandas-3.0.0\n",
      "Successfully installed pandas-2.3.3\n",
      "\u001b[33mWARNING: Skipping google-genai as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: httpx<0.28 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (0.27.2)\n",
      "Requirement already satisfied: anyio in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpx<0.28) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/phoenix/venvs/jupyter-env/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.28) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "import os, certifi\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "!pip install -U sentence-transformers qdrant-client pandas pyarrow fastapi\n",
    "!pip install \"httpx<0.28\" \"pandas<3.0\" --upgrade\n",
    "!pip uninstall -y google-genai\n",
    "!pip install \"httpx<0.28\" --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1f410ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant (Docker / Server mode) config\n",
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 6333\n",
    "\n",
    "COLLECTION_NAME = \"banking77\"\n",
    "EMBEDDING_MODEL = \"intfloat/multilingual-e5-large\"      \n",
    "\n",
    "VECTOR_SIZE = 1024\n",
    "TOP_K = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b14988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class EmbeddingModel:\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def encode(self, texts, is_query=False):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        prefix = \"query: \" if is_query else \"passage: \"\n",
    "        texts = [prefix + t for t in texts]\n",
    "\n",
    "        return self.model.encode(\n",
    "            texts,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1624a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0                     I am still waiting on my card?     11\n",
       " 1  What can I do if my card still hasn't arrived ...     11\n",
       " 2  I have been waiting over a week. Is the card s...     11\n",
       " 3  Can I track my card while it is in the process...     11\n",
       " 4  How do I know if I will get my card, or if it ...     11,\n",
       " 10003)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://huggingface.co/datasets/PolyAI/banking77/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\"\n",
    "df = pd.read_parquet(url)\n",
    "\n",
    "df.head(), len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "593b8ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported QdrantClient: <class 'qdrant_client.qdrant_client.QdrantClient'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "print(\"Imported QdrantClient:\", QdrantClient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63cc5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleted existing collection\n",
      "‚úÖ Collection recreated with VECTOR_SIZE = 1024\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "# ‚ö†Ô∏è IMPORTANT: delete old collection with wrong dimension\n",
    "if client.collection_exists(COLLECTION_NAME):\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "    print(\"üóëÔ∏è Deleted existing collection\")\n",
    "\n",
    "# ‚úÖ Recreate with correct vector size (E5-Large = 1024)\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(\n",
    "        size=VECTOR_SIZE,   # 1024\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Collection recreated with VECTOR_SIZE =\", VECTOR_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c075e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:07<00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data ingested into Qdrant (batched)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "from tqdm import tqdm\n",
    "\n",
    "embedder = EmbeddingModel(EMBEDDING_MODEL)\n",
    "\n",
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()\n",
    "\n",
    "embeddings = embedder.encode(texts)\n",
    "\n",
    "BATCH_SIZE = 256  # safe default (you can go up to ~512)\n",
    "\n",
    "for start in tqdm(range(0, len(texts), BATCH_SIZE)):\n",
    "    end = start + BATCH_SIZE\n",
    "\n",
    "    batch_points = [\n",
    "        PointStruct(\n",
    "            id=i,\n",
    "            vector=embeddings[i].tolist(),\n",
    "            payload={\n",
    "                \"text\": texts[i],\n",
    "                \"label\": int(labels[i])\n",
    "            }\n",
    "        )\n",
    "        for i in range(start, min(end, len(texts)))\n",
    "    ]\n",
    "\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=batch_points\n",
    "    )\n",
    "\n",
    "print(\" Data ingested into Qdrant (batched)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc1a7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "def semantic_search(query, top_k=TOP_K, label_filter=None):\n",
    "    # Encode query\n",
    "    query_vector = embedder.encode(query, is_query=True)[0]\n",
    "\n",
    "    # Optional label filter\n",
    "    q_filter = None\n",
    "    if label_filter is not None:\n",
    "        q_filter = Filter(\n",
    "            must=[\n",
    "                FieldCondition(\n",
    "                    key=\"label\",\n",
    "                    match=MatchValue(value=int(label_filter))\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Query Qdrant\n",
    "    results = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=query_vector.tolist(),\n",
    "        limit=top_k,\n",
    "        query_filter=q_filter,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    # Server mode returns ScoredPoint list\n",
    "    return list(results.points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08ce4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence(results):\n",
    "    if not results:\n",
    "        return 0.0\n",
    "\n",
    "    scores = [r.score for r in results]\n",
    "\n",
    "    if len(scores) == 1:\n",
    "        return round(scores[0], 3)\n",
    "\n",
    "    top, second = scores[0], scores[1]\n",
    "    relative_gap = max(top - second, 0.0)\n",
    "    normalized = top / max(sum(scores), 1e-6)\n",
    "\n",
    "    return round((0.7 * normalized) + (0.3 * relative_gap), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f109b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_workflow(confidence):\n",
    "    if confidence >= 0.75:\n",
    "        return \"AUTO_EXECUTE_INTENT\"\n",
    "    elif confidence >= 0.50:\n",
    "        return \"ASK_CLARIFICATION\"\n",
    "    else:\n",
    "        return \"FALLBACK_TO_HUMAN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e12d470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'I lost my debit card',\n",
       " 'predicted_label': 41,\n",
       " 'confidence': 0.234,\n",
       " 'workflow': 'FALLBACK_TO_HUMAN',\n",
       " 'top_matches': [{'text': 'help, lost my card', 'label': 41, 'score': 0.894},\n",
       "  {'text': 'Help! I lost my card!', 'label': 41, 'score': 0.892},\n",
       "  {'text': 'I seem to have lost my card.', 'label': 41, 'score': 0.892}]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I lost my debit card\"\n",
    "\n",
    "results = semantic_search(query)\n",
    "\n",
    "confidence = calculate_confidence(results)\n",
    "workflow = decide_workflow(confidence)\n",
    "\n",
    "response = {\n",
    "    \"query\": query,\n",
    "    \"predicted_label\": results[0].payload[\"label\"] if results else None,\n",
    "    \"confidence\": confidence,\n",
    "    \"workflow\": workflow,\n",
    "    \"top_matches\": [\n",
    "        {\n",
    "            \"text\": r.payload.get(\"text\"),\n",
    "            \"label\": r.payload.get(\"label\"),\n",
    "            \"score\": round(r.score, 3)\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    "}\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cce4c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: I want to change my card pin\n",
      "Top label: 21\n",
      "Top score: 0.907\n",
      "\n",
      "Query: I want to know my interest rate\n",
      "Top label: 70\n",
      "Top score: 0.856\n",
      "\n",
      "Query: How much cash can I deposit in one go?\n",
      "Top label: 58\n",
      "Top score: 0.889\n",
      "\n",
      "Query: Where is the nearest branch?\n",
      "Top label: 3\n",
      "Top score: 0.841\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"I want to change my card pin\", \n",
    "    \"I want to know my interest rate\", \n",
    "    \"How much cash can I deposit in one go?\",\n",
    "    \"Where is the nearest branch?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    results = semantic_search(q)\n",
    "    print(\"\\nQuery:\", q)\n",
    "    print(\"Top label:\", results[0].payload[\"label\"])\n",
    "    print(\"Top score:\", round(results[0].score, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "671bce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: ‡§Æ‡•à‡§Ç‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§°‡•á‡§¨‡§ø‡§ü ‡§ï‡§æ‡§∞‡•ç‡§° ‡§ñ‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à\n",
      "Top label: 41\n",
      "Top score: 0.912\n",
      "\n",
      "Query: ATM se paisa nahi nikla but amount debit ho gaya\n",
      "Top label: 46\n",
      "Top score: 0.895\n",
      "\n",
      "Query: net banking login nahi ho raha\n",
      "Top label: 3\n",
      "Top score: 0.851\n",
      "\n",
      "Query: UPI ‡§™‡•á‡§Æ‡•á‡§Ç‡§ü ‡§´‡•á‡§≤ ‡§π‡•ã ‡§ó‡§Ø‡§æ\n",
      "Top label: 25\n",
      "Top score: 0.89\n",
      "\n",
      "Query: cash withdrawal ke liye exchange rate galat hai\n",
      "Top label: 76\n",
      "Top score: 0.907\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"‡§Æ‡•à‡§Ç‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§°‡•á‡§¨‡§ø‡§ü ‡§ï‡§æ‡§∞‡•ç‡§° ‡§ñ‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à\", \n",
    "    \"ATM se paisa nahi nikla but amount debit ho gaya\", \n",
    "    \"net banking login nahi ho raha\",\n",
    "    \"UPI ‡§™‡•á‡§Æ‡•á‡§Ç‡§ü ‡§´‡•á‡§≤ ‡§π‡•ã ‡§ó‡§Ø‡§æ\", \n",
    "    \"cash withdrawal ke liye exchange rate galat hai\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    results = semantic_search(q)\n",
    "    print(\"\\nQuery:\", q)\n",
    "    print(\"Top label:\", results[0].payload[\"label\"])\n",
    "    print(\"Top score:\", round(results[0].score, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a33a237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: I want to change my card pin\n",
      "Predicted label: 21\n",
      "Top score: 0.907\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 21 | Score: 0.907 | Text: I would like to change the the PIN on my card.\n",
      "2. Label: 21 | Score: 0.902 | Text: I need to change my card PIN.\n",
      "3. Label: 21 | Score: 0.896 | Text: Can I change my card PIN?\n",
      "\n",
      "================================================================================\n",
      "Query: I want to know my interest rate\n",
      "Predicted label: 70\n",
      "Top score: 0.856\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 70 | Score: 0.856 | Text: I want to know the source of my funds.\n",
      "2. Label: 32 | Score: 0.853 | Text: i need to know about exchange rates\n",
      "3. Label: 70 | Score: 0.849 | Text: I would like to verify my source of funds.\n",
      "\n",
      "================================================================================\n",
      "Query: How much cash can I deposit in one go?\n",
      "Predicted label: 58\n",
      "Top score: 0.889\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 58 | Score: 0.889 | Text: How do I deposit cash?\n",
      "2. Label: 58 | Score: 0.884 | Text: What are the steps for depositing cash into my account?\n",
      "3. Label: 58 | Score: 0.883 | Text: Where can I deposit cash to top up?\n",
      "\n",
      "================================================================================\n",
      "Query: Where is the nearest branch?\n",
      "Predicted label: 3\n",
      "Top score: 0.841\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 3 | Score: 0.841 | Text: What is the closest ATM?\n",
      "2. Label: 3 | Score: 0.833 | Text: What's the closest place to withdraw money?\n",
      "3. Label: 3 | Score: 0.831 | Text: Where is the closest ATM I can use?\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"I want to change my card pin\", \n",
    "    \"I want to know my interest rate\", \n",
    "    \"How much cash can I deposit in one go?\",\n",
    "    \"Where is the nearest branch?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    results = semantic_search(q)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Query:\", q)\n",
    "\n",
    "    # Top prediction (same as before)\n",
    "    print(\"Predicted label:\", results[0].payload[\"label\"])\n",
    "    print(\"Top score:\", round(results[0].score, 3))\n",
    "\n",
    "    # NEW: Top-3 semantic matches\n",
    "    print(\"\\nTop 3 semantic search results:\")\n",
    "    for i, r in enumerate(results[:3], start=1):\n",
    "        print(\n",
    "            f\"{i}. Label: {r.payload['label']} | \"\n",
    "            f\"Score: {round(r.score, 3)} | \"\n",
    "            f\"Text: {r.payload['text']}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f09af304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: card ka pin kaise change karte hain?\n",
      "Predicted label: 21\n",
      "Top score: 0.928\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 21 | Score: 0.928 | Text: Do you know how to change my card PIN?\n",
      "2. Label: 21 | Score: 0.925 | Text: Can I change my card PIN?\n",
      "3. Label: 21 | Score: 0.923 | Text: How do I change my card PIN?\n",
      "\n",
      "================================================================================\n",
      "Query: card ka pin change kar sakte hain?\n",
      "Predicted label: 21\n",
      "Top score: 0.935\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 21 | Score: 0.935 | Text: Do you know how to change my card PIN?\n",
      "2. Label: 21 | Score: 0.932 | Text: Can I change my card PIN?\n",
      "3. Label: 21 | Score: 0.922 | Text: How do I change my card PIN?\n",
      "\n",
      "================================================================================\n",
      "Query: mera interest rate kitna hai?\n",
      "Predicted label: 76\n",
      "Top score: 0.857\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 76 | Score: 0.857 | Text: what is the exchange rate when i get cash\n",
      "2. Label: 76 | Score: 0.856 | Text: how come my withdrawal rate is wrong for my cash withdrawal\n",
      "3. Label: 56 | Score: 0.854 | Text: What is the fee to top-up my account\n",
      "\n",
      "================================================================================\n",
      "Query: ek baari mein kitna cash deposit ho sakta hai?\n",
      "Predicted label: 6\n",
      "Top score: 0.88\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 6 | Score: 0.88 | Text: Where is my cash deposit in my balance?\n",
      "2. Label: 58 | Score: 0.877 | Text: how do i get top up with cash deposit\n",
      "3. Label: 58 | Score: 0.875 | Text: how do i find top up for cash deposit\n",
      "\n",
      "================================================================================\n",
      "Query: mere sabse paas wali branch kaunsi hai?\n",
      "Predicted label: 38\n",
      "Top score: 0.851\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 38 | Score: 0.851 | Text: In regards to the PIN of the card?\n",
      "2. Label: 60 | Score: 0.848 | Text: is there a limit on top ups\n",
      "3. Label: 60 | Score: 0.845 | Text: Do you have any top-up limits?\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"card ka pin kaise change karte hain?\", \n",
    "    \"card ka pin change kar sakte hain?\",\n",
    "    \"mera interest rate kitna hai?\", \n",
    "    \"ek baari mein kitna cash deposit ho sakta hai?\",\n",
    "    \"mere sabse paas wali branch kaunsi hai?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    results = semantic_search(q)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Query:\", q)\n",
    "\n",
    "    # Top prediction (same as before)\n",
    "    print(\"Predicted label:\", results[0].payload[\"label\"])\n",
    "    print(\"Top score:\", round(results[0].score, 3))\n",
    "\n",
    "    # NEW: Top-3 semantic matches\n",
    "    print(\"\\nTop 3 semantic search results:\")\n",
    "    for i, r in enumerate(results[:3], start=1):\n",
    "        print(\n",
    "            f\"{i}. Label: {r.payload['label']} | \"\n",
    "            f\"Score: {round(r.score, 3)} | \"\n",
    "            f\"Text: {r.payload['text']}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ee06c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§ï‡§æ‡§∞‡•ç‡§° ‡§™‡§ø‡§® ‡§ï‡•à‡§∏‡•á ‡§¨‡§¶‡§≤ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?\n",
      "Predicted label: 21\n",
      "Top score: 0.917\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 21 | Score: 0.917 | Text: Do you know how to change my card PIN?\n",
      "2. Label: 21 | Score: 0.915 | Text: How do I change my card PIN?\n",
      "3. Label: 21 | Score: 0.915 | Text: Can I change my card PIN?\n",
      "\n",
      "================================================================================\n",
      "Query: ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•á ‡§ï‡§æ‡§∞‡•ç‡§° ‡§ï‡§æ ‡§™‡§ø‡§® ‡§¨‡§¶‡§≤ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?\n",
      "Predicted label: 21\n",
      "Top score: 0.921\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 21 | Score: 0.921 | Text: Can I change my card PIN?\n",
      "2. Label: 21 | Score: 0.919 | Text: Do you know how to change my card PIN?\n",
      "3. Label: 21 | Score: 0.91 | Text: May I change my PIN?\n",
      "\n",
      "================================================================================\n",
      "Query: ‡§Æ‡•á‡§∞‡§æ ‡§¨‡•ç‡§Ø‡§æ‡§ú ‡§¶‡§∞ ‡§ï‡§ø‡§§‡§®‡§æ ‡§π‡•à?\n",
      "Predicted label: 56\n",
      "Top score: 0.871\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 56 | Score: 0.871 | Text: What is the fee to top-up my account\n",
      "2. Label: 56 | Score: 0.863 | Text: what is the fee for a transfer into my account\n",
      "3. Label: 32 | Score: 0.856 | Text: What's the foreign exchange rate I will receive?\n",
      "\n",
      "================================================================================\n",
      "Query: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ï‡§ø‡§§‡§®‡§æ ‡§®‡§ï‡§¶ ‡§ú‡§Æ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?\n",
      "Predicted label: 47\n",
      "Top score: 0.841\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 47 | Score: 0.841 | Text: How long will it take for my money to be deposited?\n",
      "2. Label: 60 | Score: 0.839 | Text: what is the most money i can top up?\n",
      "3. Label: 19 | Score: 0.836 | Text: How much can I withdrawal in one month without incurring fees?\n",
      "\n",
      "================================================================================\n",
      "Query: ‡§Æ‡•á‡§∞‡•á ‡§∏‡§¨‡§∏‡•á ‡§®‡§ú‡§º‡§¶‡•Ä‡§ï ‡§µ‡§æ‡§≤‡•Ä ‡§∂‡§æ‡§ñ‡§æ ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§π‡•à?\n",
      "Predicted label: 3\n",
      "Top score: 0.865\n",
      "\n",
      "Top 3 semantic search results:\n",
      "1. Label: 3 | Score: 0.865 | Text: Where is the closest ATM to me?\n",
      "2. Label: 3 | Score: 0.857 | Text: How far is the closest ATM from me?\n",
      "3. Label: 3 | Score: 0.854 | Text: Where is the closest ATM I can use?\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§ï‡§æ‡§∞‡•ç‡§° ‡§™‡§ø‡§® ‡§ï‡•à‡§∏‡•á ‡§¨‡§¶‡§≤ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?\",\n",
    "    \"‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•á ‡§ï‡§æ‡§∞‡•ç‡§° ‡§ï‡§æ ‡§™‡§ø‡§® ‡§¨‡§¶‡§≤ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?\",\n",
    "    \"‡§Æ‡•á‡§∞‡§æ ‡§¨‡•ç‡§Ø‡§æ‡§ú ‡§¶‡§∞ ‡§ï‡§ø‡§§‡§®‡§æ ‡§π‡•à?\",\n",
    "    \"‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ï‡§ø‡§§‡§®‡§æ ‡§®‡§ï‡§¶ ‡§ú‡§Æ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?\",\n",
    "    \"‡§Æ‡•á‡§∞‡•á ‡§∏‡§¨‡§∏‡•á ‡§®‡§ú‡§º‡§¶‡•Ä‡§ï ‡§µ‡§æ‡§≤‡•Ä ‡§∂‡§æ‡§ñ‡§æ ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§π‡•à?\"\n",
    "]\n",
    "\n",
    "\n",
    "for q in queries:\n",
    "    results = semantic_search(q)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Query:\", q)\n",
    "\n",
    "    # Top prediction (same as before)\n",
    "    print(\"Predicted label:\", results[0].payload[\"label\"])\n",
    "    print(\"Top score:\", round(results[0].score, 3))\n",
    "\n",
    "    # NEW: Top-3 semantic matches\n",
    "    print(\"\\nTop 3 semantic search results:\")\n",
    "    for i, r in enumerate(results[:3], start=1):\n",
    "        print(\n",
    "            f\"{i}. Label: {r.payload['label']} | \"\n",
    "            f\"Score: {round(r.score, 3)} | \"\n",
    "            f\"Text: {r.payload['text']}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0710232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
